{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export and import venv: https://stackoverflow.com/questions/14684968/how-to-export-virtualenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>Collecting all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.animation \n",
    "import numpy as np\n",
    "import requests \n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from itertools import chain\n",
    "from datetime import date\n",
    "from typing import List\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>Read and Prepare Patentdata for further modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read files inside folder for patent data\n",
    "\n",
    "wd = os.getcwd()\n",
    "wd2 = wd + \"/Patentdata\"\n",
    "def find_excel_files_in(directory:pathlib.Path) -> List[pathlib.Path]:\n",
    "    files:List[pathlib.Path] = list()\n",
    "    for filepath in directory.rglob('*.xlsx'):\n",
    "        if filepath.is_file():\n",
    "            files.append(filepath)\n",
    "\n",
    "    return files\n",
    "\n",
    "# List of your directories\n",
    "directories:List[str] = [format(wd2)]\n",
    "\n",
    "found_files:List[pathlib.Path] = list()\n",
    "\n",
    "for directory in directories:\n",
    "    directory:pathlib.Path = pathlib.Path(directory)\n",
    "    found_files.extend(find_excel_files_in(directory))\n",
    "\n",
    "#read excel files\n",
    "listoffiles=[]\n",
    "for count,files in enumerate(found_files):\n",
    "    globals()[f\"data{count}\"] = pd.read_excel(files)\n",
    "    listoffiles.append(globals()[f\"data{count}\"])\n",
    "\n",
    "if len(listoffiles) > 1:\n",
    "    data = pd.concat(listoffiles)\n",
    "else:\n",
    "    data = globals()[f\"data{count}\"]\n",
    "\n",
    "#columnnames: delete \"-\"\n",
    "data.columns = data.columns.str.replace(\"-\",\"\")\n",
    "\n",
    "#columnnames: replace double whitespace with \"_\"\n",
    "data.columns = data.columns.str.replace(\"  \",\"_\")\n",
    "\n",
    "#columnnames: lowercase and replace whitespace with \"_\"\n",
    "data.columns= data.columns.str.lower()\n",
    "data.columns = data.columns.str.replace(\" \",\"_\")\n",
    "\n",
    "#columnnames: replace \"/\" with \"_or_\"\n",
    "data.columns = data.columns.str.replace(\"/\",\"_or_\")\n",
    "\n",
    "#columnnames: delete \",\"\n",
    "data.columns = data.columns.str.replace(\",\",\"\")\n",
    "\n",
    "#columnnames: replace \"=\" with \"equals\"\n",
    "data.columns = data.columns.str.replace(\"=\",\"equals\")\n",
    "\n",
    "#specific columnvalues: apply lowercase\n",
    "specific_columns = [\"title\",\"assignee_or_applicant\",\"optimized_assignee\",\"inventor\",\"abstract\",\"claims\",\n",
    "                    \"dead_or_alive_inpadoc_family_status\"]\n",
    "\n",
    "for i in range(len(specific_columns)):\n",
    "    data[f\"{specific_columns[i]}\"]=data[f\"{specific_columns[i]}\"].str.lower()\n",
    "\n",
    "#specific columnvalues: to string\n",
    "specific_columns.append(\"inpadoc_family_members\")\n",
    "for i in range(len(specific_columns)):\n",
    "    data[f\"{specific_columns[i]}\"]=data[f\"{specific_columns[i]}\"].astype(\"string\")\n",
    "\n",
    "#delete duplicate publication_numbers\n",
    "data = data.drop_duplicates(subset=\"publication_number\", keep='last')\n",
    "\n",
    "#reset index\n",
    "data.reset_index(inplace= True)\n",
    "data = data.drop(\"index\", axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>Read and prepare translationaldata in order to modify patentdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#read files inside folder for translation of publication Number \n",
    "\n",
    "wd = os.getcwd()\n",
    "wd2 = wd + \"/TranslationData\"\n",
    "def find_excel_files_in(directory:pathlib.Path) -> List[pathlib.Path]:\n",
    "    \n",
    "    files:List[pathlib.Path] = list()\n",
    "    for filepath in directory.rglob('*.xlsx'):\n",
    "        if filepath.is_file():\n",
    "            files.append(filepath)\n",
    "\n",
    "    return files\n",
    "\n",
    "# List of your directories\n",
    "directories:List[str] = [format(wd2)]\n",
    "\n",
    "found_files:List[pathlib.Path] = list()\n",
    "\n",
    "for directory in directories:\n",
    "    directory:pathlib.Path = pathlib.Path(directory)\n",
    "    found_files.extend(find_excel_files_in(directory))\n",
    "\n",
    "#read excel files\n",
    "\n",
    "for files in found_files:\n",
    "    xls = pd.ExcelFile(files)\n",
    "\n",
    "file = pd.read_excel(xls, \"PUBLNR\",skiprows=2)\n",
    "\n",
    "filter = file[\"DOCDB\"] != \" \"\n",
    "file = file[filter]\n",
    "\n",
    "#Filling all empty cells in the country code(CC) column inside file df\n",
    "\n",
    "for x in range(len(file)):\n",
    "    if file.iloc[x][0] != \" \":\n",
    "        shortcode_for_country = file.iloc[x][0]\n",
    "    if file.iloc[x][0] == \" \":\n",
    "        file.iloc[x][0] = shortcode_for_country\n",
    "    if file.iloc[x][1] != \" \":\n",
    "        countryname = file.iloc[x][1]\n",
    "    if file.iloc[x][1] == \" \":\n",
    "        file.iloc[x][1] = countryname\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#read ST.30 Sheet in excel file for creating \"simplified_status\",patent_status and patent_status_description\n",
    "df1_additional = pd.read_excel(xls, 'ST30_Pub availability',skiprows = 2)\n",
    "df1_additional = df1_additional[[\"Unnamed: 0\", \"Kindcode\", \"ST.30\"]].astype(\"string\").fillna(\" \")\n",
    "df1_additional.reset_index(inplace= True)\n",
    "df1_additional = df1_additional.drop(\"index\", axis = 1)\n",
    "df1_additional[\"Kindcode\"] = df1_additional[\"Kindcode\"].str.replace(\" \",\"\")\n",
    "#Filling all empty cells in the country code(CC) column\n",
    "\n",
    "for x in range(len(df1_additional)):\n",
    "    if df1_additional.iloc[x][0] != \" \":\n",
    "        shortcode_for_country = df1_additional.iloc[x][0]\n",
    "    if df1_additional.iloc[x][0] == \" \":\n",
    "        df1_additional.loc[df1_additional.index[x], 'Unnamed: 0'] = f\"{shortcode_for_country}\"\n",
    "\n",
    "#Concatenating all different types of documents into one Column\n",
    "\n",
    "file = file.groupby(['CC','Description','DOCDB'])['Type of document'].apply(', '.join).reset_index()\n",
    "\n",
    "for col in [\"Type of document\"]:\n",
    "    file[col]=file[col].str.split(\", \").map(set).str.join(\", \")\n",
    "file[\"Type of document\"] = file[\"Type of document\"].str.replace(', ','| ')\n",
    "\n",
    "#Translation summary of the type of document\n",
    "df1_translation = pd.read_excel(xls, 'ST30_Pub availability',skiprows = 0)\n",
    "df1_translation = df1_translation[[\"ST.30\",\"Description XML element\"]].astype(\"string\").fillna(\" \")\n",
    "filter = df1_translation[\"ST.30\"] != \" \"\n",
    "df1_translation = df1_translation[filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>modification of patentdata using translationaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Comparing columns from both data frames(file and data) to fill the column 'Country' in the data df\n",
    "data[\"Country\"] = \"\"\n",
    "liste1=[]\n",
    "fileCC = list(file.CC)\n",
    "fileDescription = list(file.Description)\n",
    "datapubnum = list(data[\"publication_number\"].str[0:2])\n",
    "for i in range(len(data.publication_number)):\n",
    "    for x in range(len(fileCC)):    \n",
    "        if datapubnum[i]== fileCC[x]:\n",
    "            data.loc[i,'Country'] = file.loc[x,\"Description\"]\n",
    "            break\n",
    "#Inserting a \"Type of document\" column\n",
    "#Comparing the last two indexes to the DOCDB column to determine the type of document\n",
    "#Comparing the last index to the DOCDB column to determine the type of document\n",
    "data[\"type_of_document\"] = \"\"\n",
    "liste2=[]\n",
    "fileDOCDB = list(file.DOCDB)\n",
    "data_Country = list(data.Country)\n",
    "#file_description = list(file.Description)\n",
    "file_type_of_doc = list(file[\"Type of document\"])\n",
    "datapubnum1 = list(data[\"publication_number\"].str[-2:])\n",
    "datapubnum_1 = list(data[\"publication_number\"].str[-1:])\n",
    "\n",
    "for i in range(len(data.publication_number)):\n",
    "    for x in range(len(fileDOCDB)):\n",
    "        if datapubnum1[i]  == fileDOCDB[x] and data_Country[i] == fileDescription[x]:\n",
    "            data.loc[i,\"type_of_document\"] = file.loc[x,\"Type of document\"]\n",
    "            break\n",
    "        if datapubnum_1[i]  == fileDOCDB[x] and data_Country[i] == fileDescription[x]:\n",
    "            data.loc[i,\"type_of_document\"] = file.loc[x,\"Type of document\"]\n",
    "            break   \n",
    "#Making a new column comparing two df\n",
    "#The Kindcode from df1_additional df and publication number from the data df\n",
    "#Numbers compared and inserted(450,470, A44 etc), each number represents a type\n",
    "#of document\n",
    "data[\"ST.30\"] = \"\"\n",
    "liste3= []\n",
    "df1_additional_ST_30 = list(df1_additional[\"ST.30\"])\n",
    "df1_additional_Unnamed = list(df1_additional[\"Unnamed: 0\"])\n",
    "df1_additional_Kindcode = list(df1_additional.Kindcode)\n",
    "for i in range(len(data.publication_number)):\n",
    "    for x in range(len(df1_additional)):\n",
    "        if datapubnum1[i]  == df1_additional_Kindcode[x]:\n",
    "            if datapubnum[i] == df1_additional_Unnamed[x]: \n",
    "                data.loc[i,'ST.30'] = df1_additional.loc[x,'ST.30']\n",
    "                break\n",
    "        if datapubnum_1[i]  == df1_additional_Kindcode[x]:\n",
    "            if datapubnum[i] == df1_additional_Unnamed[x]:\n",
    "                data.loc[i,'ST.30'] = df1_additional.loc[x,'ST.30']\n",
    "                break\n",
    "#create simplified_status column; look at df1_translation for changes\n",
    "data[\"simplified_status\"]= data.apply(lambda x: \"granted\" if x[\"ST.30\"]== \"450\" or x[\"ST.30\"]==\"470\"\n",
    "                                                         else \"not granted\",axis=1)\n",
    "                            \n",
    "data[\"patent_status_description\"] = \"\"\n",
    "data_ST_30 = list(data[\"ST.30\"])\n",
    "df1_translation_ST_30 = list(df1_translation[\"ST.30\"])\n",
    "for i in range(len(data.publication_number)):\n",
    "    for x in range(len(df1_translation)):\n",
    "  \n",
    "        if data_ST_30[i]  == df1_translation_ST_30[x]:\n",
    "            data.loc[i,\"patent_status_description\"] = df1_translation.loc[x,'Description XML element']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#elimniate brackets (perhaps this is already done before)\n",
    "data.rename(columns={'claims_(english)': 'claims_english'}, inplace=True)\n",
    "#make claims lowercase\n",
    "data[\"claims_english\"] = data[\"claims_english\"].str.lower()\n",
    "#not 100% sure if this one is necessary\n",
    "# data.claims_english = data.claims_english.fillna('')\n",
    "# make a split so we have each claim on its own\n",
    "data[\"claims_english\"] = data.apply(lambda x: str(x[\"claims_english\"]).split(\" | \"),axis = 1)\n",
    "# function to delete entries in claims, where first element in list was just a string and no actual claim\n",
    "data[\"claims_english\"] = data.apply(lambda x : x[\"claims_english\"] if \"1\" in x[\"claims_english\"][0] else x[\"claims_english\"][1:], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>Modification for claims(english) inside patentdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get a new df with the necessary information\n",
    "data_claims = data[[\"publication_number\", \"claims_english\"]]\n",
    "#Create column CC so we can filter for US (this was for a view only and can be replaced with Musas Code later)\n",
    "data_claims[\"CC\"] = data_claims[\"publication_number\"].str[:2]\n",
    "#Explode the dataframe, so we have a row for each single claim\n",
    "data_claims = data_claims.explode(\"claims_english\").reset_index(drop=True)\n",
    "#create new columns with the count of the words in combs\n",
    "combs=[\"use\",\"method\",\"mixture\",\"process\"]\n",
    "\n",
    "for i in combs:\n",
    "\n",
    "    data_claims[f\"count_{i}\"] = data_claims.claims_english.str.count(f\"{i}\")\n",
    "\n",
    "#create columns which indicate which type of claim it is\n",
    "data_claims[\"use\"] = data_claims.apply(lambda x: int(1) if x[\"count_use\"] > 0 and x[\"CC\"] != \"US\" else 0,axis = 1)\n",
    "data_claims[\"method\"] = data_claims.apply(lambda x: int(1) if (x[\"count_method\"] > 0 or x[\"count_process\"] > 0) and x[\"use\"] == 0 \n",
    "                                                           else 0,axis = 1)\n",
    "data_claims[\"mixture\"] = data_claims.apply(lambda x: int(1) if x[\"use\"] == 0 and x[\"method\"] == 0 and pd.notnull(x[\"claims_english\"]) \n",
    "                                                            else 0,axis = 1)\n",
    "#groupby the publication number, so we have numbers od different claim type for each patent\n",
    "data_claims_final = data_claims.groupby(\"publication_number\").sum()\n",
    "#drop the counters and country code\n",
    "data_claims_final = data_claims_final.drop(columns = [\"count_use\", \"count_method\", \"count_process\", \"count_mixture\"])\n",
    "#join the numbers of claim type with the original data (needs to be adjusted according to dataframe names)\n",
    "data = data.join(data_claims_final, on = \"publication_number\")\n",
    "#add the number of claims in each patent (this can or could be done before perhaps)\n",
    "data[\"len_claims\"] = data.claims_english.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>Check if some patents are missing inside inpadoc_family_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].fillna(\"\")\n",
    "data[\"inpadoc_family_members\"] = data.apply(lambda x: x[\"inpadoc_family_members\"] \n",
    "                                                        if len(x[\"inpadoc_family_members\"]) > 4 \n",
    "                                                        else \"\",axis=1 )\n",
    "#check if publication number has been added to inpadoc_family_members and if not add it\n",
    "data[\"inpadoc_family_members\"] = data.apply(lambda x: str(x[\"publication_number\"])+ \" | \" +str(x[\"inpadoc_family_members\"]) \n",
    "                                            if str(x[\"publication_number\"]) not in str(x[\"inpadoc_family_members\"]) else str(x[\"inpadoc_family_members\"])\n",
    "                                            ,axis = 1)\n",
    "#prepare inpadoc_family_members_column\n",
    "data[\"inpadoc_family_members\"] = data.apply(lambda x: str(x[\"inpadoc_family_members\"]).split(\" | \"),axis = 1)\n",
    "\n",
    "#remove entries which are too short in inpadoc_family_members\n",
    "for x in range(len(data)):\n",
    "    cell = data.loc[x,\"inpadoc_family_members\"]\n",
    "    for k in cell:\n",
    "        if len(k) < 5:\n",
    "            cell.remove(k)\n",
    "    if cell != data.loc[x,\"inpadoc_family_members\"]:\n",
    "        data.loc[x,\"inpadoc_family_members\"] = cell\n",
    "\n",
    "#x is a list of publicationnumbers\n",
    "#df is the dataframe\n",
    "def find_members(x,df):\n",
    "    #create empty lists for loop\n",
    "    global inpadoc_undo_nested\n",
    "    global inpadoc_family_members_find_list\n",
    "    global add_members\n",
    "    add_members = \"\"\n",
    "    inpadoc_family_members_find_list = []\n",
    "    inpadoc_undo_nested = []\n",
    "    #checklist with all publicationnumbers\n",
    "    checklist = str(df[\"publication_number\"])\n",
    "    for k in x:\n",
    "        #filter possible false entries inside column\n",
    "        if len(k) > 4:\n",
    "            inpadoc_family_members_find_list.append(k)\n",
    "        else:\n",
    "            continue\n",
    "        if k in checklist:\n",
    "            #unlist publicationnumbers inside patentfamily\n",
    "            family_members = list(chain.from_iterable(list(df.loc[df[\"publication_number\"]==str(k),\"inpadoc_family_members\"])))\n",
    "            for members in family_members:\n",
    "                #filter possible false entries inside column\n",
    "                if len(members) > 4:\n",
    "                    inpadoc_family_members_find_list.append(members)\n",
    "                    list(chain.from_iterable(inpadoc_family_members_find_list))\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            continue\n",
    "    return inpadoc_family_members_find_list\n",
    "#This function includes the \"find_members\" function. It might be the case that the \"inpadoc_family_members\"-column is incomplete\n",
    "#for some patents. The following function searches through every patentfamily for each publication number and creates a common list for\n",
    "#all patents inside a patentfamily. This Code could also be used if a new row is being added with an updated version of the patent family. \n",
    "#This will lead to an update for all previous patents inside the data.\n",
    "def iteration_of_find_members(x,df):\n",
    "    global inpadoc_undo_nested\n",
    "    global inpadoc_family_members_find_list\n",
    "    inpadoc_family_members_find_list = []\n",
    "    inpadoc_undo_nested = []  \n",
    "    global run0\n",
    "    run0 = find_members(x,df)\n",
    "    run1 = find_members(run0,df)\n",
    "    test1 = run0\n",
    "    test2 = run1\n",
    "    k= 0\n",
    "    #This function searches for patents inside a family as long as the list doesn't get longer anymore\n",
    "    while set(test1) != set(test2):\n",
    "        globals()[f\"run1\"] = find_members(run0,df)\n",
    "        test1 = run1\n",
    "        globals()[f\"run0\"] = find_members(run1,df)\n",
    "        test2 = run0\n",
    "        k=+1\n",
    "    return list(set(test2))\n",
    "\n",
    "#creating len of inpadoc_family_members\n",
    "data[\"len_inpadoc\"] = data.apply(lambda x: len(x[\"inpadoc_family_members\"]),axis = 1)\n",
    "#creating copy of data df for check up\n",
    "test = data\n",
    "test[\"test\"] = test.apply(lambda x: iteration_of_find_members(x[\"inpadoc_family_members\"],test),axis = 1)\n",
    "test[\"len_inpadoc\"] = test.apply(lambda x: len(x[\"inpadoc_family_members\"]),axis = 1)\n",
    "test[\"len_test\"] = test.apply(lambda x: len(x[\"test\"]),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 30>Export Dataframe to /Prepared_Data folder in .csv and .xlsx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.to_csv(f\"{wd+'/Prepared_Data'}/generated_data_{str(date.today()).replace('-','_')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.to_excel(f\"{wd+'/Prepared_Data'}/generated_data_{str(date.today()).replace('-','_')}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25fa845e918d32a3b2e4acbd0e5e34886fcd2db8e370ac8d1e470b5341306bb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
