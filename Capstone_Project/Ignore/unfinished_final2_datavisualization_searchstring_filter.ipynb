{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=20>\n",
    "Insert filter here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignee = \"shell oil company\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>\n",
    "Import Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.animation \n",
    "#import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "\n",
    "import requests \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "#import contextily as ctx\n",
    "#from shapely.geometry import Point\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>read files inside folder for translational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files inside folder for translational data\n",
    "\n",
    "\n",
    "from typing import List\n",
    "import pathlib\n",
    "wd = os.getcwd()\n",
    "wd = wd+\"/Prepared_Data\"\n",
    "def find_excel_files_in(directory:pathlib.Path) -> List[pathlib.Path]:\n",
    "    \n",
    "    files:List[pathlib.Path] = list()\n",
    "    for filepath in directory.rglob('*.csv'):\n",
    "        if filepath.is_file():\n",
    "            files.append(filepath)\n",
    "\n",
    "    return files\n",
    "\n",
    "# List of your directories\n",
    "directories:List[str] = [format(wd)]\n",
    "\n",
    "found_files:List[pathlib.Path] = list()\n",
    "\n",
    "for directory in directories:\n",
    "    directory:pathlib.Path = pathlib.Path(directory)\n",
    "    found_files.extend(find_excel_files_in(directory))\n",
    "\n",
    "#read excel files\n",
    "import pandas as pd\n",
    "\n",
    "#print(files)\n",
    "    #Deleting all empty rows in the file df\n",
    "for files in found_files:\n",
    "    data = pd.read_csv(files)\n",
    "\n",
    "#filter for assignee/applicants\n",
    "\n",
    "\n",
    "#Prepare a compare column for assignee filter\n",
    "assignee2 = assignee.lower()\n",
    "assignee2 = assignee2.replace(\" \",\"\")\n",
    "data[\"compare\"] = data[\"optimized_assignee\"]\n",
    "data[\"compare\"] =data[\"compare\"].str.lower()\n",
    "data[\"compare\"] =data[\"compare\"].str.replace(\" \",\"\")\n",
    "#converting inpadoc_family_members back to list\n",
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].str.replace(\"'\",\"\")\n",
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].str.replace(\"[\",\"\")\n",
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].str.replace(\"]\",\"\")\n",
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].str.replace(\" \",\"\")\n",
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].fillna(\"\")\n",
    "data[\"inpadoc_family_members\"] = data.apply(lambda x: x[\"inpadoc_family_members\"] \n",
    "                                                        if len(x[\"inpadoc_family_members\"]) > 4 \n",
    "                                                        else \"\",axis=1 )\n",
    "#check if publication number has been added to inpadoc_family_members and if not add it\n",
    "data[\"inpadoc_family_members\"] = data.apply(lambda x: str(x[\"publication_number\"])+ \" | \" +str(x[\"inpadoc_family_members\"]) \n",
    "                                            if str(x[\"publication_number\"]) not in str(x[\"inpadoc_family_members\"]) else str(x[\"inpadoc_family_members\"])\n",
    "                                            ,axis = 1)\n",
    "\n",
    "#prepare inpadoc_family_members_column\n",
    "data[\"inpadoc_family_members\"] = data.apply(lambda x: str(x[\"inpadoc_family_members\"]).split(\",\"),axis = 1)\n",
    "\n",
    "#data[\"inpadoc_family_members\"] = data.apply(lambda x: x[\"inpadoc_family_members_list\"].split(\",\"),axis = 1)\n",
    "\n",
    "#apply filter\n",
    "data = data[data[\"compare\"]==assignee2]\n",
    "data.drop(\"compare\",axis = 1,inplace = True)\n",
    "#inpadoc_family_members_list = list(pre_data[\"inpadoc_family_members\"])\n",
    "\n",
    "#look for other members in the family\n",
    "#inpadoc_family_members_list = rerun_slower(inpadoc_family_members_list,data)\n",
    "#data[data[\"publication_number\"].isin(inpadoc_family_members_list)]\n",
    "\n",
    "#creation of comparable dataframe\n",
    "data_compare = data\n",
    "\n",
    "\n",
    "#creation of df containg every family member as entry even tho some data might not exists \n",
    "publication_number = []\n",
    "inpadoc_family = []\n",
    "listdata = list(data.inpadoc_family_members)\n",
    "for i in range(len(listdata)):\n",
    "    for k in range(len(listdata[i])):\n",
    "        #print(str(i)+\"   \"+str(k)+\"list:\"+listdata[i][k])\n",
    "        publication_number.append(listdata[i][k])\n",
    "        inpadoc_family.append(listdata[i])\n",
    "d = {'publication_number': publication_number,\n",
    "    'inpadoc_family_members': inpadoc_family}\n",
    "data_family = pd.DataFrame(data=d)\n",
    "#make column inpadoc_family_members mergable\n",
    "data[\"inpadoc_family_members\"] = data[\"inpadoc_family_members\"].astype(\"string\")\n",
    "data_family[\"inpadoc_family_members\"] = data_family[\"inpadoc_family_members\"].astype(\"string\")\n",
    "#merge\n",
    "data_family = data_family.merge(data_compare, right_on=['publication_number','inpadoc_family_members'],left_on=['publication_number','inpadoc_family_members'],how=\"left\")\n",
    "\n",
    "data_family.reset_index(inplace= True)\n",
    "data_family = data_family.drop(\"index\", axis = 1)\n",
    "#drop duplicates\n",
    "data_family = data_family.drop_duplicates(subset=[\"publication_number\"], keep=\"first\")\n",
    "data = data_family\n",
    "\n",
    "#DATA ADJUSTMENTS\n",
    "\n",
    "#read files inside folder for translation of publication Number \n",
    "\n",
    "wd = os.getcwd()\n",
    "from typing import List\n",
    "import pathlib\n",
    "wd2 = wd + \"/Translationaldata\"\n",
    "def find_excel_files_in(directory:pathlib.Path) -> List[pathlib.Path]:\n",
    "    \n",
    "    files:List[pathlib.Path] = list()\n",
    "    for filepath in directory.rglob('*.xlsx'):\n",
    "        if filepath.is_file():\n",
    "            files.append(filepath)\n",
    "\n",
    "    return files\n",
    "\n",
    "# List of your directories\n",
    "directories:List[str] = [format(wd2)]\n",
    "\n",
    "found_files:List[pathlib.Path] = list()\n",
    "\n",
    "for directory in directories:\n",
    "    directory:pathlib.Path = pathlib.Path(directory)\n",
    "    found_files.extend(find_excel_files_in(directory))\n",
    "\n",
    "#read excel files\n",
    "import pandas as pd\n",
    "\n",
    "#print(files)\n",
    "    #Deleting all empty rows in the file df\n",
    "for files in found_files:\n",
    "    xls = pd.ExcelFile(files)\n",
    "\n",
    "file = pd.read_excel(xls, \"PUBLNR\",skiprows=2)\n",
    "\n",
    "filter = file[\"DOCDB\"] != \" \"\n",
    "file = file[filter]\n",
    "\n",
    "#Filling all empty cells in the country code(CC) column inside file df\n",
    "\n",
    "for x in range(len(file)):\n",
    "    if file.iloc[x][0] != \" \":\n",
    "        shortcode_for_country = file.iloc[x][0]\n",
    "    if file.iloc[x][0] == \" \":\n",
    "        file.iloc[x][0] = shortcode_for_country\n",
    "    if file.iloc[x][1] != \" \":\n",
    "        countryname = file.iloc[x][1]\n",
    "    if file.iloc[x][1] == \" \":\n",
    "        file.iloc[x][1] = countryname\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#read ST.30 Sheet in excel file for creating \"simplified_status\",patent_status and patent_status_description\n",
    "df1_additional = pd.read_excel(xls, 'ST30_Pub availability',skiprows = 2)\n",
    "df1_additional = df1_additional[[\"Unnamed: 0\", \"Kindcode\", \"ST.30\"]].astype(\"string\").fillna(\" \")\n",
    "df1_additional.reset_index(inplace= True)\n",
    "df1_additional = df1_additional.drop(\"index\", axis = 1)\n",
    "df1_additional[\"Kindcode\"] = df1_additional[\"Kindcode\"].str.replace(\" \",\"\")\n",
    "# #Filling all empty cells in the country code(CC) column\n",
    "\n",
    "for x in range(len(df1_additional)):\n",
    "    if df1_additional.iloc[x][0] != \" \":\n",
    "        shortcode_for_country = df1_additional.iloc[x][0]\n",
    "    if df1_additional.iloc[x][0] == \" \":\n",
    "        df1_additional.loc[df1_additional.index[x], 'Unnamed: 0'] = f\"{shortcode_for_country}\"\n",
    "\n",
    "#Concatenating all different types of documents into one Column\n",
    "\n",
    "file = file.groupby(['CC','Description','DOCDB'])['Type of document'].apply(', '.join).reset_index()\n",
    "\n",
    "for col in [\"Type of document\"]:\n",
    "    file[col]=file[col].str.split(\", \").map(set).str.join(\", \")\n",
    "file[\"Type of document\"] = file[\"Type of document\"].str.replace(', ','| ')\n",
    "\n",
    "#Translation summary of the type of document\n",
    "df1_translation = pd.read_excel(xls, 'ST30_Pub availability',skiprows = 0)\n",
    "df1_translation = df1_translation[[\"ST.30\",\"Description XML element\"]].astype(\"string\").fillna(\" \")\n",
    "filter = df1_translation[\"ST.30\"] != \" \"\n",
    "df1_translation = df1_translation[filter]\n",
    "\n",
    "#Comparing columns from both data frames(file and data) to fill the column 'Country' in the data df\n",
    "data.drop(\"country\",axis = 1,inplace = True)\n",
    "data[\"Country\"] = \"\"\n",
    "for i in range(len(data.publication_number)):\n",
    "    #print(f'1 {i}')\n",
    "    for x in range(len(file.CC)):\n",
    "        #print(f'2 {x}')\n",
    "        if data[\"publication_number\"].iloc[i][0:2] == file.CC.iloc[x]:\n",
    "            #print(f'3 {data[\"publication_number\"].iloc[i][0:2]}')\n",
    "            #print(f'4 {file.CC.iloc[x]}')  \n",
    "            data.loc[i,'Country'] = file.loc[x,\"Description\"]\n",
    "            break\n",
    "\n",
    "\n",
    "#Inserting a \"Type of document\" column\n",
    "#Comparing the last two indexes to the DOCDB column to determine the type of document\n",
    "#Comparing the last index to the DOCDB column to determine the type of document\n",
    "data[\"type_of_document\"] = \"\"\n",
    "\n",
    "for i in range(len(data.publication_number)):\n",
    "    #print(f'1 {i}')\n",
    "    for x in range(len(file.DOCDB)):\n",
    "        #print(f'2 {x}')\n",
    "        if data[\"publication_number\"].iloc[i][-2:]  == file.DOCDB.iloc[x] and data[\"Country\"].iloc[i] == file.Description.iloc[x]:\n",
    "            #print(f'3 {data[\"publication_number\"].iloc[i][0:2]}')\n",
    "            #print(f'4 {file.CC.iloc[x]}')  \n",
    "            #data['type_of_document'].iloc[i] = file[\"Type of document\"].iloc[x]\n",
    "            \n",
    "            data.loc[i,\"type_of_document\"] = file.loc[x,\"Type of document\"]\n",
    "            break\n",
    "        if data[\"publication_number\"].iloc[i][-1:]  == file.DOCDB.iloc[x] and data[\"Country\"].iloc[i] == file.Description.iloc[x]:\n",
    "            #print(f'3 {data[\"publication_number\"].iloc[i][0:2]}')\n",
    "            #print(f'4 {file.CC.iloc[x]}')  \n",
    "            data.loc[i,\"type_of_document\"] = file.loc[x,\"Type of document\"]\n",
    "\n",
    "            break\n",
    "        \n",
    "#Making a new column comparing two df\n",
    "#The Kindcode from df1_additional df and publication number from the data df\n",
    "#Numbers compared and inserted(450,470, A44 etc), each number represents a type\n",
    "#of document\n",
    "\n",
    "data[\"ST.30\"] = \"\"\n",
    "for i in range(len(data.publication_number)):\n",
    "    #print(f'1 {i}')\n",
    "    for x in range(len(df1_additional)):\n",
    "        #print(f'2 {x}')\n",
    "        if data[\"publication_number\"].iloc[i][-2:]  == df1_additional[\"Kindcode\"].iloc[x]:\n",
    "            if data[\"publication_number\"].iloc[i][0:2] == df1_additional[\"Unnamed: 0\"].iloc[x]:\n",
    "            #print(f'3 {data[\"publication_number\"].iloc[i][0:2]}')\n",
    "            #print(f'4 {file.CC.iloc[x]}')  \n",
    "                data.loc[i,'ST.30'] = df1_additional.loc[x,'ST.30']\n",
    "                break\n",
    "        if data[\"publication_number\"].iloc[i][-1:]  == df1_additional[\"Kindcode\"].iloc[x]:\n",
    "            if data[\"publication_number\"].iloc[i][0:2] == df1_additional[\"Unnamed: 0\"].iloc[x]:\n",
    "            #print(f'3 {data[\"publication_number\"].iloc[i][0:2]}')\n",
    "            #print(f'4 {file.CC.iloc[x]}')  \n",
    "                data.loc[i,'ST.30'] = df1_additional.loc[x,'ST.30']\n",
    "                break\n",
    "\n",
    "#create simplified_status column; look at df1_translation for changes\n",
    "data[\"simplified_status\"]= data.apply(lambda x: \"granted\" if x[\"ST.30\"]== \"450\" or x[\"ST.30\"]==\"470\"\n",
    "                                                         else \"not granted\",axis=1)\n",
    "                            \n",
    "data[\"patent_status_description\"] = \"\"\n",
    "for i in range(len(data.publication_number)):\n",
    "\n",
    "    for x in range(len(df1_translation)):\n",
    "  \n",
    "        if data[\"ST.30\"].iloc[i]  == df1_translation[\"ST.30\"].iloc[x]:\n",
    "            data.loc[i,\"patent_status_description\"] = df1_translation.loc[x,'Description XML element']\n",
    "            break\n",
    "#make data columns lowercase\n",
    "data.columns = data.columns.str.lower()\n",
    "#hong kong to china in order to be displayed in worldmap later\n",
    "data[\"country\"] = data.apply(lambda x: \"china\" if x[\"country\"]== 'hong kong (s.a.r.)' else x[\"country\"],axis =1)\n",
    "\n",
    "\n",
    "\n",
    "#create data for total and add it to data df\n",
    "#Creating 3 dataframes: All, Granted, Not-Granted with new column total_of_publication_number respectively\n",
    "from pandas import NA\n",
    "\n",
    "total_column = data[data['country'].values != \"\"]\n",
    "total_column = total_column[[\"publication_number\",\"country\"]].groupby('country').agg('count')\n",
    "total_column.rename(columns = {\"publication_number\" : \"total_of_publication_number\"}, inplace = True)\n",
    "total_column.reset_index(inplace = True)\n",
    "total_column[\"total_of_publication_number\"] = total_column.apply(lambda x: NA if x[\"total_of_publication_number\"] == 0 else x[\"total_of_publication_number\"],axis = 1)\n",
    "data_all_total = data.merge(total_column, left_on = 'country', right_on = 'country', how='left')\n",
    "#data_all_total\n",
    "\n",
    "#create data for proportion and add it to data df BUT FOR GRANTED ONLY\n",
    "prestep= data[data['country'].values != \"\"]\n",
    "total_column = prestep[prestep[\"simplified_status\"] == \"granted\"]\n",
    "if len(total_column) == 0:\n",
    "    data_granted_total = None\n",
    "    print(\"WARNING: no patents are granted with this filter\")\n",
    "else:\n",
    "    total_column = total_column[[\"publication_number\",\"country\"]].groupby('country').agg('count')\n",
    "    total_column.rename(columns = {\"publication_number\" : \"total_of_publication_number\"}, inplace = True)\n",
    "    total_column.reset_index(inplace = True)\n",
    "    total_column[\"total_of_publication_number\"] = total_column.apply(lambda x: NA if x[\"total_of_publication_number\"] == 0 else x[\"total_of_publication_number\"],axis = 1)\n",
    "    data_granted_total = data.merge(total_column, left_on = 'country', right_on = 'country', how='left')\n",
    "    #data_granted_total\n",
    "\n",
    "#create data for proportion and add it to data df BUT FOR NOT-GRANTED ONLY\n",
    "prestep= data[data['country'].values != \"\"]\n",
    "total_column = prestep[prestep[\"simplified_status\"] == \"not granted\"]\n",
    "if len(total_column) == 0:\n",
    "    data_not_granted_total = None\n",
    "    print(\"WARNING: no patents are not-granted with this filter\")\n",
    "    \n",
    "else:\n",
    "    total_column = total_column[[\"publication_number\",\"country\"]].groupby('country').agg('count')\n",
    "    total_column.rename(columns = {\"publication_number\" : \"total_of_publication_number\"}, inplace = True)\n",
    "    total_column.reset_index(inplace = True)\n",
    "    total_column[\"total_of_publication_number\"] = total_column.apply(lambda x: NA if x[\"total_of_publication_number\"] == 0 else x[\"total_of_publication_number\"],axis = 1)\n",
    "    data_not_granted_total = data.merge(total_column, left_on = 'country', right_on = 'country', how='left')\n",
    "    #data_not_granted_total\n",
    "\n",
    "\n",
    "\n",
    "#get current working directory\n",
    "\n",
    "current_wd = os.getcwd()\n",
    "path_worldmap= \"/Worldmap/World_Countries.shp\"\n",
    "path_worldmap = current_wd+path_worldmap\n",
    "#read worldmap shape file\n",
    "world_map = gpd.read_file(path_worldmap)\n",
    "#make country names lowercase in order to match dataframes by countrynames\n",
    "world_map[\"COUNTRY\"]=world_map[\"COUNTRY\"].str.lower()\n",
    "world_map.sort_values(by = \"COUNTRY\")\n",
    "#adjust important names for merging\n",
    "world_map[\"COUNTRY\"] = world_map[\"COUNTRY\"].str.replace(\"united states\", \"united states of america\")\n",
    "world_map[\"COUNTRY\"] = world_map[\"COUNTRY\"].str.replace(\"south korea\", \"korea (south)\")\n",
    "world_map[\"COUNTRY\"] = world_map[\"COUNTRY\"].str.replace(\"moldova\", \"republic of moldova\")\n",
    "world_map[\"COUNTRY\"] = world_map[\"COUNTRY\"].str.replace(\"russia\", \"russian federation\")\n",
    "\n",
    "#merge dataframes\n",
    "if data_all_total is not None:  \n",
    "    merged_all = world_map.merge(data_all_total, left_on = 'COUNTRY', right_on = 'country', how='outer')\n",
    "    merged_all['total_of_publication_number'] = merged_all['total_of_publication_number'].fillna(0)\n",
    "else:\n",
    "    print(\"WARNING: no patents exists using this filter\")\n",
    "#merge granted\n",
    "if data_granted_total is not None:\n",
    "    merged_granted = world_map.merge(data_granted_total, left_on = 'COUNTRY', right_on = 'country', how='outer')\n",
    "    merged_granted['total_of_publication_number'] = merged_granted['total_of_publication_number'].fillna(0)\n",
    "else:\n",
    "    print(\"WARNING: no patents are granted using this filter\")\n",
    "if data_not_granted_total is not None:\n",
    "    merged_not_granted = world_map.merge(data_not_granted_total, left_on = 'COUNTRY', right_on = 'country', how='outer')\n",
    "    merged_not_granted['total_of_publication_number'] = merged_not_granted['total_of_publication_number'].fillna(0)\n",
    "else:\n",
    "    print(\"WARNING: no patents are not granted using this filter\")\n",
    "\n",
    "\n",
    "#create list of countries that are not on the world map\n",
    "\n",
    "countries_not_on_map = []\n",
    "for element in list(total_column[\"country\"]):\n",
    "    if element not in list(world_map[\"COUNTRY\"]):\n",
    "        countries_not_on_map.append(element)\n",
    " \n",
    "print(\"Values that can't be shown in the plot, since they are not assigned to a country: \\n\"+str(countries_not_on_map))\n",
    "\n",
    "#extract proportions for if \"country\" is no actual country\n",
    "nocountries = total_column[\"country\"].isin(countries_not_on_map)\n",
    "nocountries = total_column[nocountries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>Check if filter works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data) == 0:\n",
    "    print(\"WARNING: no data available using this filter\")\n",
    "    print(\"number of patents in the dataframe: \"+str(len(data)))\n",
    "else:\n",
    "    print(\"filter application works\")\n",
    "    print(\"number of patents in the dataframe: \"+str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>Creation of Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def round_up_to_nearest_10(num):\n",
    "    return math.ceil(num / 10) * 10\n",
    "\n",
    "round_up_to_nearest_10(21)\n",
    "\n",
    "#plot worldmap ALL\n",
    "def plot_worldmap(df,situational,status):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from matplotlib import cm\n",
    "    from matplotlib.colors import TwoSlopeNorm\n",
    "    import statistics\n",
    "\n",
    "    #statistics.median(percentage_column[\"proportion_of_publication_number\"])\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "    #divider = make_axes_locatable(ax)\n",
    "\n",
    "    #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "    # create a normalized colorbar\n",
    "    #norm = TwoSlopeNorm(vmin=min(total_column[\"total_of_publication_number\"]),\n",
    "    #                vcenter=statistics.median(total_column[\"total_of_publication_number\"]),\n",
    "    #                vmax=max(total_column[\"total_of_publication_number\"]))\n",
    "    cmap=plt.cm.get_cmap('plasma', 50)\n",
    "    #cbar = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "    #creating values for tick in legend; 20 ticks\n",
    "    ticks = []\n",
    "    for x in range(1,21):\n",
    "        ticks.append(x/10*round_up_to_nearest_10(max(df[\"total_of_publication_number\"])))\n",
    "\n",
    "    tick_label = []\n",
    "    for x in range(1,21):\n",
    "       tick_label.append(x/10*round_up_to_nearest_10(max(df[\"total_of_publication_number\"])))\n",
    "\n",
    "    #not in use yet\n",
    "    legend_label = []\n",
    "    for x in range(1,21):\n",
    "        legend_label.append(f\"{round(x/20*max(df['total_of_publication_number']),0)}%\")\n",
    "        #legend_label\n",
    "\n",
    "    fig = df.plot(ax = ax,markersize = 100,column = 'total_of_publication_number', figsize=(20,10),\n",
    "                                                     cmap=cmap,\n",
    "                                                     # create a normalized colorbar\n",
    "                                                     #cbar = plt.cm.ScalarMappable(norm=norm),  \n",
    "                                                     legend = True,\n",
    "                                                    \n",
    "                                                     legend_kwds={'label': 'Number of Patents',\n",
    "                                                                    #'title_fontsize':20,\n",
    "                                                                    'orientation': \"horizontal\",\n",
    "                                                                    'pad': 0.04,\n",
    "                                                                    'fraction': 0.09,\n",
    "                                                                   # 'norm': norm,\n",
    "                                                                    'ticks':ticks\n",
    "                                                                    #\"fmt\":\"{:%}\"\n",
    "                                                                    \n",
    "                                                                    },\n",
    "                                                     missing_kwds={\n",
    "                                                                 \"color\":\"grey\",\n",
    "                                                                 \"edgecolor\":\"black\",\n",
    "                                                                 \"hatch\":\"---\",\n",
    "                                                                 \"label\":\"Missing Values\"\n",
    "                                                                },\n",
    "                                                     vmin=0, vmax=round_up_to_nearest_10(max(df[\"total_of_publication_number\"]))\n",
    "                                                     )\n",
    "\n",
    "\n",
    "    #include no countries in the title\n",
    "    #creation of string\n",
    "    #preparation for no country entries\n",
    "    nocountries_string =f\"{str(nocountries.iloc[0][0])}: {str(round(nocountries.iloc[0][1],2))}% \\n \"\n",
    "    #nocountries_string\n",
    "    for i in range(len(nocountries)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        nocountries_string = nocountries_string + f\"{str(nocountries.iloc[i][0])}: {str(round(nocountries.iloc[i][1],2))}% \\n \"\n",
    "\n",
    "    #ax_cbar = fig.colorbar(cbar, ax=ax)\n",
    "    #plt.legend(title = \"lol\",loc = \"lower center\")\n",
    "    \n",
    "    from datetime import datetime\n",
    "    now = datetime.now()\n",
    "    plt.title(f\"{now.strftime('%d/%m/%Y %H:%M')}\", loc='right', fontsize=15, color='grey', style='italic')\n",
    "    plt.tick_params(left = False, bottom = False)\n",
    "\n",
    "    #preparing the making of a condition for how many of the patents are actually in the data\n",
    "    data_av_pubnum = list(df[\"publication_number\"].dropna())\n",
    "    data_notav_pubnum = list(data[\"publication_number\"])\n",
    "    count = int(0)\n",
    "    for x in data_av_pubnum:\n",
    "        if x in data_notav_pubnum:\n",
    "            count +=1\n",
    "    #ax.axes.set_xticklabels(tick_label)\n",
    "    if situational is not None:\n",
    "\n",
    "        plt.title(f\"Worldwide distribution of {status} patents\\n{assignee} | family members:{len(situational[situational['publication_number'].notnull()])}\", fontsize = 30, loc = \"left\",y = 1.01,style = 'italic')\n",
    "        \n",
    "    else:\n",
    "        #check\n",
    "        if count == len(data_av_pubnum):\n",
    "            plt.title(f\"Worldwide distribution of {status} patents\\n{assignee} | total claims:{df['len_claims'].sum()}\", fontsize = 30, loc = \"left\",y = 1.01,style = 'italic')\n",
    "        else:\n",
    "            plt.title(f\"Worldwide distribution of {status} patents\\n{assignee}\", fontsize = 30, loc = \"left\",y = 1.01,style = 'italic')\n",
    "    #make condition for how many of the patents are actually in the data\n",
    "    \n",
    "        \n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_worldmap_for_each_family(df,status):\n",
    "    if \"total_of_publication_number\" in df.columns:\n",
    "        df.drop(\"total_of_publication_number\",axis = 1, inplace = True)\n",
    "    families = data_all_total[\"inpadoc_family_members\"].unique()\n",
    "    for i in families:\n",
    "        if i is NA:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            situational_data = df[df[\"inpadoc_family_members\"]== i]\n",
    "            #create column with aggregated count of patents country-wise\n",
    "            total_column = situational_data[situational_data['country'].values != \"\"]\n",
    "            total_column = total_column[[\"publication_number\",\"country\"]].groupby('country').agg('count')\n",
    "            total_column.rename(columns = {\"publication_number\" : \"total_of_publication_number\"}, inplace = True)\n",
    "            total_column.reset_index(inplace = True)\n",
    "            total_column[\"total_of_publication_number\"] = total_column.apply(lambda x: NA if x[\"total_of_publication_number\"] == 0 else x[\"total_of_publication_number\"],axis = 1)\n",
    "            situational_data = situational_data.merge(total_column, left_on = 'country', right_on = 'country', how='left')\n",
    "            #data_all_total\n",
    "            situational_data= world_map.merge(situational_data, left_on = 'COUNTRY', right_on = 'country', how='outer')\n",
    "            situational_data['total_of_publication_number'] =situational_data['total_of_publication_number'].fillna(0)\n",
    "\n",
    "            #create variables for text showoff\n",
    "            text = [f\"countries and their total count:\\n\"]\n",
    "            unique_countries = situational_data.country.dropna().unique()\n",
    "            for k in unique_countries:\n",
    "                countries = k\n",
    "                values = str(int(situational_data[situational_data[\"country\"]==str(k)][[\"total_of_publication_number\"]].agg('count')))\n",
    "                text.append(f\"{countries}: {values} \\n\")\n",
    "            print(f\"length of the family: {len(situational_data[situational_data['publication_number'].notnull()])} \\nthe family: {i}\\n{''.join(text)}\\n{plot_worldmap(situational_data,situational_data,status)}\")\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>Plot for all patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for all patents (granted and not granted)\n",
    "plot_worldmap_for_each_family(data_all_total,\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>Plot for only granted patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for only granted patents\n",
    "plot_worldmap_for_each_family(data_granted_total,\"granted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=20>Plot for only NOT-granted patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for only NOT-granted patents\n",
    "plot_worldmap_for_each_family(data_not_granted_total,\"not granted\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nf_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab3d85a18739f6fff6a9c8c504adc2ff9340867b576dede986e2ee74c099e4e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
